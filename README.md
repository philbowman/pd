# ACCURATE INTERPRETATION


        **_My interpretation can only be as inerrant as I am, and that's good to keep in mind._**


                            **-Rachel Held Evans**


    Assessments generate evidence. Both teachers and students interpret the results of the evidence before they take action. The quality of their actions will depend on the accuracy of their interpretations. _Accurate interpretation _involves teachers and students drawing similar inferences from assessment results. The accuracy of these interpretations is critical, as this information influences the instructional responses that follow. Although psychometricians note problems, Sarah M. Bonner (2013) contends that "validity or appropriateness of inferences' ' is a core value in classroom assessment practices (p. 87). In fact, Bonner (2013) calls for developing new methods to help and guide teachers to ensure their inferences are sound and interpreted and perceived accurately. When interpretations are accurate, teachers can make more solid instructional decisions for using assessments formatively and more valid and reliable evaluations for communicating achievement to learners and families. Equally if not more important, students require accurate interpretations of their results _to align with those of their teacher _so that they can accomplish four significant tasks: (1) identify their personal strengths and opportunities to grow, (2) clarify the kinds of instructional strategies that work best for them, (3) establish goals to guide next steps, and (4) engage in an


                _59_


    instructional partnership with the teacher to accomplish their goals. In the absence of accurate and consistent interpretations of the results, teachers run the risk of losing the students' investment to address the remaining gaps.


    In his work regarding assessment, Rick Stiggins (2007) is fervent and consistent in his belief that the number-one instructional decision maker in every classroom is the learner. It is fair to say, then, that both teachers and learners must be able to cultivate data in meaningful ways to promote continued learning. Ultimately, data must offer both instructional decision makers-learner and teacher alike--clear and accurate information that provides insight into next steps. The interpretation of results must be accurate, accessible, and reliable.


    _Interpretation _is about giving meaning to inferences drawn from data, which include student work, the numbers, the grades, the marks, the feedback, and even the context, plus what we know or believe about students. These data (and the inferences we draw) lead to conclusions that influence teacher and student actions and inform student beliefs and confidence.


    When these inferences are inaccurate, they lead students and teachers to judgments and decisions that can be misleading or damaging to a learner's confidence. Inaccurate inferences also lead to decisions that waste valuable time and resources for both the teacher and the learner, as outlined in the following scenario.


###### 
        Traditional Scenario


        _Sabrina, Marcel, and Ava are members of a fourth-grade team focused on using assessment to help students achieve more. Each teacher entered his or her students' scores into a spreadsheet for a quiz intended to assess reading comprehension.The quiz consisted of five multiple-choice questions, four short­ response questions, and one long-response question. They divided the students_


        _into three groups according to the number of points they received. Students who received nine or ten were in Group A; students who scored seven or eight points were in Group B; and students who got six or fewer were in Group C. Once they put students in groups, the teachers assigned a different task.They assumed Group A could read independently and comprehend well, so they got free-choice time._


        _Group B got a few questions wrong, so the teachers assumed this group needed a little more practice. They got another text and some more questions to answer. Group C needed more of the previous instruction to walk through the passage more slowly and revisit the key details and core ideas the teachers had hoped the learners would glean from the initial reading. As planned, each teacher worked with the core instruction group and walked students through the passage._




        _Upon reporting back, the team of teachers was incredibly frustrated. While the teachers had all implemented their plan in their own classrooms, each found that Group A was off task and became a distraction to Group B.The students in Group C showed frustration and kept asking why they were doing this. They, too, were off task. The team seemed to have no indication about the final impact of its assigned task. The teachers were left with the question, Did this help students learn more? Their assessment indicated their efforts did not lead to more learning._


    When teachers, like students, see only the facts of an assessment (the percent correct), the interpretation of the results can be inaccurate, unreliable, or inaccessible. In this case, significant and meaningful insights regarding appropriate instructional maneuvers for the teacher and the learner are blurred by broad or overarching summations.


    **Understanding the Third Tenet: Accurate Interpretation**


    Each of the three criteria for generating quality interpretations-(!) accuracy,


    (2) accessibility, and (3) reliability-serves a distinct purpose. They are significant in their own right but most powerful when aligned. In other words, an assessment that offers only one of the three criteria is only marginally more powerful than an assessment that has none of the three criteria. To begin; it's important to understand what each criterion entails.


    _Accuracy _is the extent to which the information precisely reflects a student's level of understanding or skill on a particular standard or set of standards. A precise reflection of learning should indicate as much about what a learner has mastered as what he or she hasn't mastered and why. Accurate interpretations delineate each learner's specific misconceptions or errors. Assessments can only be deemed accurate through a cultivation and exploration of the resulting student artifacts or evidence. More importantly, accuracy is critical to dearly communicate learning to students--both for the purposes of feedback to learn and grow, as well as to report a snapshot of achievement at various points throughout a school year. Chapter 3 (page 41) more thoroughly discusses the attributes of communication, but interpreting the assessment design and the process that teachers employ and facilitate must be accurate to lead to quality communication.


    If an accurate interpretation is kept secret, no one benefits. So, the interpretation of results must also be _accessible. _Teachers leverage accessibility of the results to ensure that the interpretations are dear and meaningful to both teachers and learners. In the previous scenario, the fourth-grade team found its quiz scores didn't mean much in terms of measuring learning, so the decisions teachers made did not improve student learning or positively influence confidence. Instead, their decisions led to frustration for teachers and students alike. In the assessment design, the structure


    and organization of items and tasks must lead learners and teachers to ascertain information about learning strengths and next steps. In using the data, the student work or observations must offer insight into understanding and misconceptions so that learners and teachers apply an action that has more likelihood to improve achievement and confidence (as students recognize they get better when they take action).


    This also means that teachers must provide students with opportunity and access to their assessment information, including ways to reflect on the information so that teachers know how learners are interpreting their scores and what impact those scores are having on their confidence and achievement. When Maya, a fourth grader, returned from school, she showed her mom a mathematics assessment. At the top it read, "-3 wrong," "85%," "B" for a letter grade, and "3" for the level of proficiency against the standard. When asked what she thought this meant, Maya replied, "I don't know, and it doesn't really matter." There were four different indicators of Maya's achievement-none of which helped her or her mother figure out what to do to improve and none of which suggested that improvements would change or update the score. These types of data-numbers, letters, check marks, and so on-make marking easier for the teacher and attempt to provide insight to the key stakeholders (parent, administrator, student, and teacher). But, what does it all really mean? While we might assume Maya has a pretty good handle on the learning goals being assessed, it is unclear what she actually understands and what she still needs to learn. High­ quality data practices inspire action through accurate and accessible information to students about what they have learned and how they can grow. Chapter 7 (page 111) on student investment digs deeper into the self-regulation that is possible when assessment information is interpreted well.


    Finally, interpretation of the results must include _reliability. _Accurate and accessible results can be deemed inequitable if reliability is not taken into consideration. When it comes to the results of an assessment, reliability is found in the degree of stability and consistency in a variety of aspects, including these four.



1. Internal consistency (one evaluator of multiple examples or pieces of assessment evidence)
2. 	External consistency (two or more evaluators of one or more examples of assessment evidence)
3. Parallel assessment consistency (more than one version of an assessment)
4. Test or retest consistency

    Reliability is found in consistent results across multiple examples or evaluators. If two teachers look at the same assessment data, do they come to a consistent conclusion? How reliable or consistent are the feedback, scores, and use of assessment


    information? Teachers must work in collaboration and with intentional processes to ensure reliable data and educational equity.


    Teachers can facilitate the accurate, accessible, and reliable interpretation of their assessment results if they attend to three critical features in advance: (1) the design of the assessment, (2) the system or process they **will **use to mine the data, and (3) a preplanned notion of the actions they will take based on the results. These data and the resulting interpretations provide the foundation for decisions that teachers make in their instruction and reporting, and they also influence the decisions learners make to engage, persevere, learn more, or quit. Accurate, accessible, and reliable interpretations of assessment results are necessary-from teacher to teacher, from teacher to student, from student to teacher, and from student to student-in order for students and teachers to make solid decisions about learning.


    **Research Synthesis**


    The assessment tenet for accurate interpretation is deeply grounded in the research on validity, reliability, and fairness. Because much of the research focuses on standardized, larger-scale assessments, there is a call for more research on classroom assessment validity, reliability, and fairness and even some guiding factors to consider when teachers, students, and other stakeholders engage in examining their classroom assessment design and effective use.



## Accuracy and Validity


    _Validity _is the extent to which the assessment information accurately shows what to measure and the extent to which that information leads teachers to accurate inferences about students' understanding (or lack of understanding). Teachers can improve the accuracy of interpretations by determining what learning to measure and aligning items and tasks with this plan (Campbell & Collins, 2007; Guskey, 2005). Chapter 5 (page 77) on assessment architecture will further outline this process and its essential role in high-quality classroom assessment. The quality of assessment information interpretations increases when these types of plans-that identify learning descriptions and the accompanying items on the assessment-are used to design assessments.


    In the past, the interpretation of classroom assessment was considered low stakes because the consequences of any individual decision or interpretation on one classroom assessment didn't lead to major consequences. However, research now indicates that there are an incredible number of decisions made based on classroom assessment, and the accumulation of those decisions can have a lasting impact on a


    student's self-perception, motivation, engagement, and achievement (Bonner, 2013). It can also lead teachers or others to make general assumptions about students that sometimes are more difficult to adjust. For example, a student who gets Cs over time may leave the teacher with the impression that C work is what he or she can expect. This mindset might inadvertently cloud a teacher's interpretation of student work or assessment information. So, if a student produces and shows evidence of work that would earn a B, it may still be scored a C because of his or her past work and teacher expectations. The interpretation of results can lead to misinformation or misplacement if higher-stakes decisions about course placement are made based on grades or other interpretations of student work.


    Researchers Gloria Ladson-Billings and Mary Louise Gomez (2001) worked alongside teams of elementary school teachers monthly and helped all third graders perform at standard in reading within about eighteen months. Their monthly conversations focused on identifying students they were most concerned about and strategizing on how to support them. Prior to the support of the external facilitators, initial conversations focused on locating the problems in the students' home lives and communities-all external factors. With guidance from Ladson-Billings and Gomez (2001), the educators reshaped their conversations to be about what was in their control and then focused their discussions on learning. By redirecting or reshaping the conversation to empower teachers to recognize the patterns in the data and achievement and to keep trying new things until they saw students achieve, both students and teachers began to feel confident and achieve at higher levels. This was also a way to acknowledge that many of the students who had not been achieving and were tracked into pull-out classes and reading recovery programs were African American. The collaboration allows interpretations to be more accurate and to reduce the amount of outside factors that can get in the way for both students and teachers.


    Many factors can influence the accuracy of inferences or interpretations drawn from the evidence. One of the most important factors is what the learner brings to the assessment experience. Robert F. McMorris and Roger A. Boothroyd (1993) describes the unintended but inevitable impact of assessment on student motivation and attitude. If the assessment experience is positive, learners tend to persevere longer and have more favorable beliefs about their performance on the assessment, which in turn will help students achieve more. The opposite is also true. If Learners have a negative assessment experience, that will have negative effects on a student's confidence and achieve­


    ment. In the traditional approach to validity, teachers would try to minimize the effects the assessment experience has on the measurement. However, the ongoing nature of classroom assessments makes this impossible. So, if students feel negatively toward the assessment experience, it will impact the accuracy and meaning of the results and the kinds of interpretations that teachers and students make (Bonner, 2013).


    The process teachers use to make inferences and the subsequent decisions about how to help students learn more or what grade or score to apply also influences the accuracy of assessment. Teachers improve interpretations by sharing their assessment designs and collaboratively reviewing the results of assessment information with colleagues. These processes reduce the effects of bias, as teachers help check each other's expectations of students and any preconceived notions they may have about each student's ability (Bonner, 2013). When they collaborate, teachers can get a better sense of what students have learned as they examine student work. They can also make more accurate and fair determinations about what the assessment information means and how to best communicate that learning in terms of grades and scores (Bonner, 2013). This is true whether teachers are collaborating on common assessments (all teachers give the same assessment) or individual assessments in an interdisciplinary or vertical-team formation.


    Researchers in the field of validity explore and try to understand the ways teachers make decisions about how to support student learning and what grades to assign or proficiency scores to use. A more traditional approach to validity is difficult because the more standardized conditions and low numbers of students taking the exam make the more traditional methods not as effective or even possible (sample size and controlled conditions). However, Bonner (2013) advocates for new ways to help teachers validate their classroom assessments, including observations and information teachers interpret in the moment as more formative. It is important that teachers begin to explore ways for making their individual interpretations more accurate and meaningful.


    Both teachers _and _learners must interpret their assessment information accurately. When teachers use formative assessment practices well, they help students interpret their assessment information in ways that support and improve their learning. Ultimately, the learners have to maintain a similar interpretation of their results to their teacher's interpretation. In a study about the impact of sharing rubrics with students prior to summative assessment to improve learning, Heidi L. Andrade and Ying Du (2005) find it not only helps provide dearer expectations to students but also reduces their stress and gives them a tool to check their work and self-assess prior to the assignment deadline. When learners share the same criteria as teachers regarding their work, they too can begin to have more accurate and valid interpretations of their evidence.


## 
    Accuracy and Reliability


    While validity involves the accuracy of inferences about the evidence resulting from the assessments, _reliability _involves the consistency of these inferences. Jay Parkes (2013) identifies three concepts essential for reliability. The first is _replication. _If two teachers review the same piece of student work, do they come to the same general


    conclusion about what the student understands and what his or her next step is? Do items and tasks intended to assess a similar criterion or quality (standard) indicate a similar level of understanding by the same student? The second concept essential for reliability is _sampling observations. _In sampling observations, reliability is about noticing if the score assigned to the assessment information reflects observations a teacher made in the classroom. If there is a lack of consistency between the observations and the assessment information, there is less reliability in that assessment score. The third and final concept is _unidimensionality, _which ensures that the score reflects one quality and not a mix of many. When multiple criteria or qualities are being assessed, it is important to provide a score for each quality or learning goal. Summarizing all learning outcomes with one score reduces the meaning and the reliability of that score.


    In addition to these three concepts, teachers trying to increase reliability must also consider measurement error, the purpose of the measurement, and the "property of a score not of a test or assessment" (Parkes, 2013, p. 108). When taking error into account, teachers consider factors that influence the score other than actual knowledge of the targeted goal. This is where bias becomes problematic. What background knowledge is required to engage in the task? The more reasons students get something wrong (other than they don't know the information or can't perform the skill), the lower the reliability of that assessment. It could even be as simple as a teacher misreading a response or marking something wrong that is really right. Once teachers have more information (for example, a student or a parent points out the error), they must work with students to fix the error and provide a more accurate score. While teachers are in the driver's seat to check reliability, having an intentional process to do so will help guide this work; other stakeholders will also play a role and provide another lens to consider when assessing reliability. Parkes (2013) notes, "While the measurement community ... tends to think of reliability as consistency of measurement, the more practically helpful way for teachers to think of reliability would be to reduce errors or mistakes while assessing" (p. 109). This leads to the conclusion that teachers should work together to create reliable and accurate assessment data and practice.


    To ensure reliability, Parkes (2013) offers some direction:


        Once the samples are drawn-once the test of several items is given, once the portfolio is scored by three peers, or once a poem is recited at least twice-sufficient information exists to estimate how consistently or reliably the (single) domain has been sampled. (p. 11O)


    It appears that reliability is a process that teachers must engage in to get closer to a more accurate score. The process of reviewing work gets more reliable scores that reduce error. Daniel Starch and Edward C. Elliott (I 912) gave the same two essays


    to two hundred high schools and asked that first-year English teachers score them on a scale of 1 to 100. Scores ranged from 60 to 97 on one paper and 50 to 97 on the other. In 2011, Hunter Brimi based his own study on Starch and Elliott's work. In this study, however, teachers worked together to co-construct a rubric on a common writing framework. Of the seventy-three teacher scores collected, scores ranged from 50 to 93. Again, the reliability of these scores comes into question, even when constructing the rubric. As teachers engage in this collaborative process, they must work together to review student work to increase the reliability of the scores on assessment (Barron & Darling-Hammond, 2008).


    There is a gap in K-12 research when it comes to identifying and understanding how a teacher identifies bias in his or her informal interpretations and reflects on ensuring a more valid and reliable response to decisions made in the moment (Bonner, 2013). Identifying and eliminating---or at least minimizing-all forms of bias is critical for teachers to consider when improving the accuracy of their interpretations of assessment information. Valid and reliable inferences are necessary to inform learning, increase confidence and achievement, and better reflect learning through any reporting process.


    Data analysis is a central part of professional learning, accountability, and school­ improvement efforts. However, a focus on data that cultivates a learning-rich culture­ one that sheds light on learning strengths, inspires action, and improves learning and confidence in both learners and teachers-is an unrealized power of the information at our fingertips. Research supports three conditions that, when nurtured, tap into this power and set up strategies to foster productive responses and effective and more accurate interpretations: (1) a tone of influence and possibility, (2) a focus on strengths, and (3) attention to learning as contextual.


    A learning-rich culture provides opportunities for risk taking, productive failure, and celebrated successes for both learners and teachers. Data practices teachers engage must cultivate these attributes. These conditions are not strategies but agreements about collaboration, assessment design, and how teachers talk about the data and learners as well as what data they collect and analyze.


    **A Tone of Influence and Possibility**


    The language and actions of educators signal whether they believe it is possible for students to achieve. When they do believe all learners can learn at high levels, their conversation is focused on the things they can control. They spend little time on causes beyond their influence. Educators who believe all students can learn deliberately adopt a tone of influence and possibility as a means to promote learning, especially in the toughest situations. While the attitudes and behaviors of some learners may be frustrating and even exhausting, educators continue to speak with


    possibility about their learners and employ pronouns that reference their collective commitment to learners: _"Our _students, whom we care deeply about, struggle to write explanations. How are we going to help them take the first step?" This is in contrast to language that suggests students are stuck in a state of struggle and there is nothing that will move them forward: "Those kids just can't write." Educators who adopt a tone of influence and possibility are careful to understand their students and examine evidence through a lens of what's strong or present, rather than what's wrong or absent, and they create a narrative of opportunity (Jones & Vagle, 2013). This reduces the potential that a teacher's tone or attitude might negatively influence how students engage in their work and influences what students believe about themselves.


##### 
    A Focus on Strengths


    All too often, learners and teachers (among others) focus on all that is wrong or needs work, leading to the sense that success is a daunting task at the end of an arduous journey. Data promotes possibility and inspires action when a culture encourages a focus on strengths and uses that data to help teachers and learners see themselves as successful. With a sense of confidence built from success, actions to improve become welcome and part of the ongoing routines for both teachers and learners. This condition requires that data conversations include questions that analyze quantitative and qualitative data for strengths: What do the data indicate is working? What does the information tell us about what learners understand? Conversations begin with identifying what is in place or what is understood and then move to what is next.


##### 
    Attention to Learning as Contextual


    Teaching is not a series of strategies or activities; there is no manual or resource that can dictate every move a teacher makes or every activity or question a learner engages with. While there are research-validated strategies that have the potential to help students learn, they play out differently given the teacher's delivery, the classroom climate and routines, and who the learners are. With any strategy, teachers consider the impact on learners. The same lesson may work well during one class period and have little or no impact on the next, so context matters. Teachers also help learners recognize strategies with the biggest impact on their success. This condition is built through reflection, such as asking, "What helps students learn and what gets in the way?" and "What do they do when they get stuck?" This condition requires that teachers constantly ask, "How did what we do impact our students?" And, students ask, "How did what I did impact my learning?" This kind of questioning and reflection is key to accurate interpretations in more informal ongoing classroom assessment practices.


    These conditions guide the interpretive work of individual teachers and the conversations collaborative teams have when ensuring assessment information is accurate, reliable, and accessible.


# 
    Accurate Interpretation in the Classroom


    Interpretations of assessment information happen formally and informally. Teachers make observations and interpret information that informs their responses and the ways they engage students. This is powerful and as important as the more formal assessments-tests, projects, and performances. The following strategies focus on how teachers can increase the accuracy and reliability of their interpretations.


#### 
    Establish Criteria and Evidence to Monitor Proficiency Progress


    Interpretation starts with having a clear learning goal or standard. This learning goal provides the foundation interpretation is built on. Once the learning goals are outlined, a teacher articulates the methods used to collect information and make inferences about learners' understanding or misconceptions. In addition, clear criteria in the form of rubrics, checklists, learning progressions, and more make learning visible to students. Teachers provide direction on what kind of evidence to collect, and these are the focus areas that guide ongoing monitoring of progress. There is no time for a teacher to monitor it all, so deciding on clear criteria and what is essential provides direction for what to monitor.


    These methods must be aligned with classroom instruction (Bonner, 2013). "Poor alignment between instruction and classroom assessment can have negative impacts on student attitudes, motivation, and classroom climate" (Bonner, 2013, p. 99). Consider when you studied for a test only to find that the test covered something completely different and asked something you had no clue how to tackle. This mismatch between instruction and assessment causes many students to shut down and feel powerless; this angst will lead to more errors in assessment interpretation.


#### Use Classroom Observations to Maintain Deliberate Focus and Monitor Student Responses


    Classroom observations often lead to what is known as a _teachable moment. _Teachable moments can happen at any time; they are not planned and most likely aren't predicted. In fact, they can happen after the teacher is amazing-articulate, engaging, and masterful in asking students to have a dialogue. One comment from a learner or an observation of how a learner is making sense of the work can indicate a visible misunderstanding or error. When teachers capitalize on these moments and recognize (and interpret) that students have missed the key knowledge or skills, that interpretation can lead to improved achievement and confidence. Teachers must


    have a clear learning target to know when to stop and respond in these teachable moments, and also when to let them go or revisit them at a later time.


### Collaborate During The Development Phase


    Working with colleagues and perhaps even students to select and create items and tasks can minimize bias and create more likelihood that the assessment itself actually reflects learning and not other external factors (Kane, 2006). In some circumstances, teachers will ask students for feedback on the assessment to check interpretations of the items or tasks. It is important that chat teachers collaboratively examine student work and review the assessment results to see if there are patterns of how students respond that indicate whether they can show understanding on the item or task. In the process, teachers must also attend to any extenuating factors or circumstances that may have interfered with the assessment. They must provide formal and specific opportunities for students to reflect on their assessment experience by asking questions such as:



* What was the most difficult part of this assessment?
* What would you do differently next time?
* What was most confusing?
* What did you feel most confident about?
* What else do you know that the assessment didn't allow you to show or demonstrate?

    When teachers have new information about how to make the assessment design more accurate, they should make those revisions.


### 
    Collaborate During The Appraisal Phase


    During the appraisal phase, teachers and students are reviewing assessment evidence and data so as to develop inferences about what the assessment information means for instruction and for student learning. To validate evidence of assessment, multiple stakeholder perspectives must be taken into account, including those of colleagues. Protocols are designed to focus the work on evidence-based information versus perceptions and assumptions. It is all about the questions from teachers and the questions from students. The best protocols keep it simple, clear, and focused and remain mindful of the conditions for a learning-rich culture. The first two protocols that follow focus on data conversations for teachers, while the last protocol is for learners.



##### Protocol One: lesson Planning from Assessment Evidence


    This protocol requires the use of evidence from a classroom assessment to inform lesson design. Teachers work together or individually to identify an essential-to-learn, hard-to-learn, and hard-to-teach learning goal in the context of a unit or time frame (Dimich, 2015). They gather evidence (student work) on the identified learning goal. The evidence is **in **the form of artifacts-the actual student work from quizzes, drafts of paragraphs or essays, exit slips, bell-ringers, homework, or other student work that provides insight into the level of proficiency students have on the targeted learning goal. Teachers review the student work and make piles of the work based on the identified errors, misconceptions, and next steps within the artifacts. All the students who need to work on the same next step are stacked in the same pile. Finally, teachers design an instructional response for each stack. This process has five steps.



1. Teachers bring student work (an exit slip, a quiz, the rough draft of a paragraph, or another assessment) that shows a level of understanding on a targeted learning goal.
2. Teachers examine the work, one student at a time, asking themselves the following questions.
    1. What does this work indicate the learner knows?

        6.  What does the learner need to do to learn and grow?

1. Is there anything in the design of the assessment that contributed to the results?
2. Are there other reasons the student might have performed well or not well other than he or she knows or doesn't know the targeted learning?
3. Teachers group students with similar next steps.
4. Teachers plan an instructional lesson or activity for each group to do independently or collaboratively, depending on the task and classroom environment.
5. Teachers do a quick check, assessing the impact of the instructional lesson on learners' understanding.

    Figure 4.1 (page 72), Lesson Planning From Assessment Evidence, is a graphic organizer to help individuals and teams of teachers target their instruction based on the learning needs of their students that are uncovered in a review of the assessment evidence.


<table>
  <tr>
   <td>
    <strong>Focus Area or Next Step</strong>
<p>

    (Describe what learners need to work on or the misconception demonstrated in the work.)
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    <strong>Students</strong>
<p>

    (List learners who need each focus area.)
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    <strong>Agenda for Instruction</strong>
<p>

    (Develop an agenda or instructional plan to address their focus area.)
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>
    <strong>Materials</strong>
<p>

    (Identify resources to support each group.)
   </td>
   <td>
   </td>
  </tr>
</table>



    **_Figure 4.1: Lesson planning for assessment evidence._**


    _Visit **go.Solution Tree.com/assessment **for a free reproducible version of this figure._


    Protocol Two: Strategically Supporting Learners


    With a deliberate focus on helping teachers refocus their conversations on learners' strengths versus all they are lacking, Ladson-Billings and Gomez (2001) assisted in getting all third graders at an elementary school to perform at standard in reading. This protocol is based on the lessons from the study that cultivated a more strength­ based view of students and more deliberate attention to those students' learning. Collaborative teams in this model meet one to two times per month. This process has four steps.

1. 	Individual teachers or groups of teachers identify learners they are most concerned about achieving the course or grade's essential standards. They list the students' names.
2. At each meeting, the teachers check on the progress of those students. How are they doing? (Consider achievement, engagement, and confidence.) What has been done to help them? What is the evidence they are achieving and building confidence? What actions, strategies, or classroom environment factors are supporting this achievement? What does the evidence suggest as further support?
3. Individual teachers and the group commit to intentional action based on the evidence and progress to continue their support of those students.
4. Teachers and others who support the team (administrators and instructional coaches) identify articles, research, or websites to read more about the targeted content or grade level. These resources may be identified

        after classroom observations and evidence analysis to determine the types of resources that might best fit the context and meet student needs.


    **Protocol Three:Having Students Review Sample Work**


    When students review sample work and understand the qualities of that work, their understanding of how to achieve it grows. In this protocol, a teacher guides learners to review other students' anonymous sample works on a similar task to the one in which the learners are engaged. The goal is to increase learners' understanding of what quality work and achievement look like and, in turn, for them to be able to make adjustments and revisions to their own work. This process has six steps.

1. Identify the type of work or task and the learning target for students. Select the rubric or scoring criteria. Find six to eight sample works. Be sure all names are taken off the work, especially if using work from other students at the school--even from previous years or other classes.
2. Have students individually score each piece of work on all criteria in the rubric.
3. In groups of three, learners work together and share their scores. They must come to consensus on the score of each criterion, using evidence from the work and their interpretation of the rubric.
4. 	For each piece of work, the group identifies a strength. What does the work show the learner understands? Then, the group identifies a next step for each piece of work. What does the learner need to do to improve?
5. The class shares their reflection on the process. What is strong about the work (in general)? What needs work? How would you describe quality work for this task?
6. Individually, students reflect on their own work, identifying strengths and next steps that lead to revision and growth.

    When our assessment practices include an intentional focus on accurate interpretation, the following scenario will be a more common practice in our schools.



###### A New Vision


        _Sabrina, Marcel, and Ava are members of a fourth-grade team focused on using assessment to help students achieve more. The team chose a text that was at grade level and articulated three learning goals._



    1. / _can identify the main idea._
    2. _I can provide evidence from the text and explain how it supports the main idea._
    3. _I can make inferences about the text and connect it to another text._

        _The team designed three to five questions for each learning goal. Once students had taken this quiz, the teachers all entered the scores of the quiz by learning goal. As they worked together, they looked at all students who had scored lower on learning goal number one. From the student work, they reviewed the common errors students made and talked through whether they felt the errors_


        _were caused by the question, background knowledge, or misunderstanding in the reading. They followed the same procedure for each learning goal. After reviewing the results, they felt that goal number three was where the most students had_


        _the biggest errors. As a result, they planned instruction based on some of the instructional errors students made. They stacked all their students based on common misconceptions or next steps and had a stack of students who had mastered the target and needed enrichment. After a few minutes, they sketched out an instructional plan and a follow-up assessment to check to see the impact of their planned instruction. Each group received a set of instructions or an agenda and directions of what to submit as a group for students to show their progress._


        _The teachers planned to engage in conversations and move among the groups to ensure they were clear about the task and to make more observations about the level of understanding of their students._


        _Upon reporting back, the team was incredibly excited. Each group had made great progress. Not only were the team's observations right on, but teachers saw major growth on the follow-up reading and quiz._


    **Interpretation happens from the design of the assessment to reviewing and using the results. In the previous scenario, teachers were very clear about what they wanted to assess and could check to see if their questions gave them good information, talking through any match or mismatch in their observations. They also worked together to review the work and determine what students understood and what they missed. Checking their inferences together allowed the team members to increase the validity and reliability of their assessment information and create a more solid base for the decisions made in their instruction.**


    **Interpretation is both product and process. **It **is the design of the assessment and the process of coming to meaning-this meaning sets up feedback and grades or scores to inspire action in students and teachers. Cultivating a learning-rich culture is an intentional process that requires a deliberate focus on theory and practice to guide teachers in interpreting assessment information in more intentional ways. When**


                            **_Accurate Interpretation  _**l  _75_


    realized, the opportunities for learners to take risks, productively fail, and celebrate success will empower and inspire learners and teachers alike.



# Pause and Ponder


    Take a few moments to reflect on the following questions.



* What quote or passage encapsulates your biggest takeaway from this chapter? What immediate action will you take as a result?
* What does it mean for assessment information to be valid, accessible, and reliable?
* <sup>	</sup>Do you review assessment information to ensure interpretations are accurate and reliable? If so, how? If not, what might be a good first step?
* What are the key influences on the inferences you make from assessment information (past performance, scores, standards, or others)?
* What intentional processes are in place to help eliminate and reduce bias in interpreting assessment information in instruction? How about in your more summative assessment work?
* What happens when you find information that contradicts your original interpretations or scores?
* What changes in your process could contribute to more accurate, reliable, and accessible assessment evidence?
